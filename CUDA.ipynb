{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CUDA.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNrl5ygAYCm1c7aeAnyzXF0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mleyvaz/Programacion-II/blob/main/CUDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcScgT9RyVMt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77fe023d-27a5-4935-d200-0c251a72b3d6"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Feb  5 02:02:53 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.39       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   49C    P0    28W /  70W |    227MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUmmZGExyean"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "tf.test.gpu_device_name()\r\n",
        "# Standard output is '/device:GPU:0'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WnCmLieyhNh"
      },
      "source": [
        "import torch\r\n",
        "torch.cuda.is_available()\r\n",
        "\r\n",
        "# Output would be True if Pytorch is using GPU otherwise it would be False."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozhDUzck1fIE"
      },
      "source": [
        "torch.cuda.get_device_name()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgNocwg9zh4w"
      },
      "source": [
        "!cat /proc/meminfo #RAM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POeZyrIDznTq"
      },
      "source": [
        "!cat /proc/cpuinfo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MW4JRIv14F76"
      },
      "source": [
        "import pynvml\r\n",
        "\r\n",
        "pynvml.nvmlInit()\r\n",
        "handle = pynvml.nvmlDeviceGetHandleByIndex(0)\r\n",
        "device_name = pynvml.nvmlDeviceGetName(handle)\r\n",
        "\r\n",
        "if device_name != b'Tesla T4':\r\n",
        "  raise Exception(\"\"\"\r\n",
        "    Unfortunately this instance does not have a T4 GPU.\r\n",
        "    \r\n",
        "    Please make sure you've configured Colab to request a GPU instance type.\r\n",
        "    \r\n",
        "    Sometimes Colab allocates a Tesla K80 instead of a T4. Resetting the instance.\r\n",
        "\r\n",
        "    If you get a K80 GPU, try Runtime -> Reset all runtimes...\r\n",
        "  \"\"\")\r\n",
        "else:\r\n",
        "  print('Woo! You got the right kind of GPU!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XstsC-Sn2csI"
      },
      "source": [
        "# Install RAPIDS\r\n",
        "!git clone https://github.com/rapidsai/rapidsai-csp-utils.git\r\n",
        "!bash rapidsai-csp-utils/colab/rapids-colab.sh\r\n",
        "\r\n",
        "import sys, os\r\n",
        "\r\n",
        "dist_package_index = sys.path.index('/usr/local/lib/python3.6/dist-packages')\r\n",
        "sys.path = sys.path[:dist_package_index] + ['/usr/local/lib/python3.6/site-packages'] + sys.path[dist_package_index:]\r\n",
        "sys.path\r\n",
        "exec(open('rapidsai-csp-utils/colab/update_modules.py').read(), globals())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7kjsrmz5ywf"
      },
      "source": [
        "!pip install cudf-cuda100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "il4duQn73BDe"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "\r\n",
        "pandas_df = pd.DataFrame({'a': np.random.randint(0, 100000000, size=100000000),\r\n",
        "                          'b': np.random.randint(0, 100000000, size=100000000)})\r\n",
        "\r\n",
        "                          \r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4P1tHFbH4ZWA"
      },
      "source": [
        "# Timing Pandas\r\n",
        "# Output: 82.2 ms per loop\r\n",
        "%timeit pandas_df.a.mean()\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}